{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size = \"10\"> Week 3 - Ion Channels <center>\n",
    "<center><font size = \"8\">Tutorial 01: data files<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"><font color = \"blue\">In this tutorial you will learn:\n",
    "    \n",
    "<font size = \"3\"><font color = \"blue\">- to work and explore ion channel files \n",
    "\n",
    "<font size = \"3\"><font color = \"blue\">- to plot data from ion channel files\n",
    "    \n",
    "<font size = \"3\"><font color = \"blue\">- to fit curves to data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Open ion channel data files and plot \n",
    "\n",
    "<font size = \"3\">Take a look at the data files from this tutorial with the extension .NWB (Neurodata Without Borders). This is a specific format to store cellular-based neurophysiology data from a single experimental session (you can find more information [here](https://nwb-schema.readthedocs.io/en/latest/).\n",
    "    \n",
    "<font size = \"3\">There are several ways to open a file like that: [PyNWB](https://pynwb.readthedocs.io/en/stable/), [HDFview](https://www.hdfgroup.org/downloads/hdfview/) or Python. You can see below an example of one of the files open with HDFview.\n",
    "\n",
    " <br><img src=\"HDFViewer_IonFileDisplay.png\" width=\"800\" height=\"400\">   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\">Now let's see how to open and explore the file with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data with python\n",
    "import h5py\n",
    "\n",
    "data_path = 'files/rCell2148.nwb'\n",
    "\n",
    "data = h5py.File(data_path, 'r')\n",
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explore the data file\n",
    "# To see all the possible methods:\n",
    "# type data[('stimulus')]. and press tabular key --> this will display a list with all the possibilities\n",
    "\n",
    "print(data[('stimulus')].values)\n",
    "\n",
    "print(data[('stimulus')].keys())\n",
    "\n",
    "print (data[('stimulus/presentation/')].values)\n",
    "\n",
    "print (data[('stimulus/presentation/')].keys())   # and so on...\n",
    "\n",
    "print (data[('analysis')].values)  # this should be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file\n",
    "data_path = 'files/rCell2148.nwb'\n",
    "nwbFile = data_path\n",
    "open_data = h5py.File(nwbFile, 'r')\n",
    "\n",
    "# Select on strings what do we want for ploting\n",
    "string_data = '/acquisition/timeseries/VRest/repetitions/repetition1/data'\n",
    "\n",
    "# safe on different variables\n",
    "data = open_data[(string_data)]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Plotting data.\n",
    "\n",
    "<font size = \"3\">Now that we know how to see what is inside the file, we can plot some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotDataFiles(nwbFile, protocolName, repID, byTraces = False):\n",
    "    ''' Function .....\n",
    "    :param nwbFile: the data path to file\n",
    "    :param protocolName: protocol name defined in the data file\n",
    "    :param repID: protocol repetition number\n",
    "    :param byTraces: if true, represent each trace in one figure'''\n",
    "    \n",
    "    # Open the file\n",
    "    open_data = h5py.File(nwbFile, 'r')\n",
    "    \n",
    "    # Select on strings what do we want for ploting\n",
    "    string_data = '/acquisition/timeseries/'+ protocolName + '/repetitions/repetition' + repID +'/data'\n",
    "    string_xinterval = '/acquisition/timeseries/'+ protocolName + '/repetitions/repetition' + repID +'/x_interval'\n",
    "    string_xstart = '/acquisition/timeseries/'+ protocolName + '/repetitions/repetition' + repID +'/x_start'\n",
    "    \n",
    "    # safe on different variables\n",
    "    data = open_data[(string_data)].value\n",
    "    x_interval = open_data[(string_xinterval)].value\n",
    "    x_start = open_data[(string_xstart)].value\n",
    "    \n",
    "    # create time vector in ms\n",
    "    nRow, nCol = data.shape\n",
    "    x_end = x_start[0] + x_interval[0]*(float(nRow - 1))\n",
    "    time = np.linspace(x_start[0], x_end, nRow)*1000\n",
    "    \n",
    "    # We can plot the data in two ways:\n",
    "    # way 1: all the traces in one figure\n",
    "    if byTraces == False:\n",
    "        plt.figure()\n",
    "        plt.title('%s protocol' %protocolName)\n",
    "        plt.ylabel('voltage traces (mV)')\n",
    "        plt.xlabel('time (ms)')\n",
    "        plt.plot(time, data, 'b')\n",
    "        plt.show()\n",
    "    else:\n",
    "        # way 2: each trace in different figures\n",
    "        data_t = np.transpose(data)\n",
    "        i = 0\n",
    "        for trace in data_t:\n",
    "            plt.figure()\n",
    "            plt.title('%s protocol, trace %s' %(protocolName,i))\n",
    "            plt.ylabel('voltage traces (mV)')\n",
    "            plt.xlabel('time (ms)')\n",
    "            plt.plot(time, trace, 'b')\n",
    "            i = i + 1\n",
    "        plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the previous function and plot the Activation curves\n",
    "\n",
    "plotDataFiles(data_path, 'Deactivation', '2', byTraces=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Curve fitting\n",
    "\n",
    "<font size = \"3\">Curve fitting, also known as regression analysis, is used to find the \"best fit\" line or curve for a series of data points. Most of the time, the curve fit will produce an equation that can be used to find points anywhere along the curve. \n",
    "    \n",
    "<font size = \"3\">Here you will find two examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: linear fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1_path = 'files/stLine1.dat'\n",
    "dat2_path = 'files/stLine2.dat'\n",
    "dat3_path = 'files/stLine3.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def curveFittingStLine(fileName, fitting_values = False):\n",
    "    '''This function computes a linear regression for the data in fileName'''\n",
    "    # Open the file and separate the columns in x and y\n",
    "    df = pd.read_table(fileName, sep='\\s+', header=None)\n",
    "    x = df[0]\n",
    "    y = df[1]\n",
    "    \n",
    "    # Fitting function\n",
    "    gradient, intercept, r_value, p_value, std_err = stats.linregress(x,y) \n",
    "    # y = gradient*x + intercept\n",
    "    # gradient = slope of the regression line; float\n",
    "    # intercept = intercept of the regression line; float\n",
    "    # r_value = correlation coefficient; float\n",
    "    # p_value = two-sided p-value for a hypothesis test whose null hypothesis is that the slope is zero; float\n",
    "    # std_err = standard error of the estimated gradient; float\n",
    "    \n",
    "    # Print fitting parameters result, if we want\n",
    "    # Gradient and intercept are the parameters to be computed\n",
    "    # You can quantify the quality of the fitting\n",
    "    # by comparing r, p and std\n",
    "    if fitting_values == True:\n",
    "        print ('gradient =', gradient)\n",
    "        print ('intercept =', intercept)\n",
    "        print ('r_value =', r_value)\n",
    "        print ('p_value =', p_value)\n",
    "        print ('std_err =', std_err)\n",
    "    \n",
    "    # Prepare predicted line for plotting \n",
    "    mn=np.min(x)\n",
    "    mx=np.max(x)\n",
    "    x1=np.linspace(mn,mx,500)\n",
    "    y1=gradient*x1+intercept\n",
    "    \n",
    "    # Plot data and regresion line\n",
    "    plt.plot(x,y,'xk', x1, y1, '-r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curveFittingStLine(dat1_path, fitting_values = True)\n",
    "curveFittingStLine(dat2_path, fitting_values = True)\n",
    "curveFittingStLine(dat3_path, fitting_values = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: exponential fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat4_path = 'files/singleExp1.dat'\n",
    "dat5_path = 'files/singleExp2.dat'\n",
    "dat6_path = 'files/singleExp3.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def func_exp(x, tau):\n",
    "    return 1 - np.exp(-x/tau)\n",
    "\n",
    "def curveFittingSingleExp(fileName):\n",
    "    '''This function computes an exponential fitting for the data in fileName'''\n",
    "    # Open the file and separate the columns in x and y\n",
    "    df = pd.read_table(fileName, sep='\\s+', header=None)\n",
    "    x_data = df[0]\n",
    "    y_data = df[1]\n",
    "    \n",
    "    # In this case, we want to compute TAU = popt[0]\n",
    "    # and to quantify the fitting quality we want to know perr\n",
    "    popt, pcov = curve_fit(func_exp, x_data, y_data)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(x_data, y_data, 'xk', label='original data' )\n",
    "    plt.plot(x_data, func_exp(x_data, popt[0]), '-r',label='fit: tau=%.3f, error=%.3f' %(popt[0],perr))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curveFittingSingleExp(dat4_path)\n",
    "curveFittingSingleExp(dat5_path)\n",
    "curveFittingSingleExp(dat6_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
