{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size = \"10\"> Week 11 - Network Simulation II<center>\n",
    "<center><font size = \"8\">Tutorial 02: Spike train analysis 02 <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3'><font color='blue'> In this tutorial we will analyze the spike trains from the different cells.\n",
    "    \n",
    "<font size='3'><font color='blue'> We will stimulate each cell with a __poissonian__ stimulation.\n",
    "    \n",
    "<font size='3'><font color='blue'>Then we will compute statistics on each spike train and we will compute a crosscorrelation analysis between spike trains using [ELEPHANT](https://elephant.readthedocs.io/en/latest/index.html), a library for the analysis of electrophysiological data in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the MOD files necesary for the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nrnivmodl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load useful packages\n",
    "%matplotlib inline\n",
    "\n",
    "from neuron import h, gui\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load external files & initialize\n",
    "h.load_file(\"stdrun.hoc\");\n",
    "h.stdinit();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the class Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell:\n",
    "    def __init__(self, filename, name, cell_type):\n",
    "        self.name = name\n",
    "        self.type = cell_type\n",
    "        self.synapses = []\n",
    "        self.build_morphology(filename)\n",
    "        self.biophysics()\n",
    "        \n",
    "    def build_morphology(self, filename):\n",
    "        h.load_file('import3d.hoc')\n",
    "        h.load_file('stdlib.hoc')\n",
    "        #morph_reader = h.Import3d_Neurolucida3()\n",
    "        morph_reader = h.Import3d_SWC_read()\n",
    "        morph_reader.input(filename)\n",
    "        i3d = h.Import3d_GUI(morph_reader, 0)\n",
    "        i3d.instantiate(self) # Notice this change to be able to instantiate several cells\n",
    "    \n",
    "    def biophysics(self):\n",
    "        for sec in h.allsec():\n",
    "            sec.Ra = 100    # Axial resistance in Ohm * cm\n",
    "            sec.cm = 1      # Membrane capacitance in micro Farads / cm^2\n",
    "            sec.insert(\"pas\")\n",
    "            for seg in sec:\n",
    "                seg.pas.g = 0.00003\n",
    "                seg.pas.e = -75\n",
    "        \n",
    "        # Insert passive current in the dendrite\n",
    "        for sec in self.soma:\n",
    "            sec.insert('hh')\n",
    "            for seg in sec:\n",
    "                seg.hh.gnabar = 0.12  # Sodium conductance in S/cm2\n",
    "                seg.hh.gkbar = 0.036  # Potassium conductance in S/cm2\n",
    "        \n",
    "        if hasattr(self, 'apic'):\n",
    "            for sec in self.apic:\n",
    "                sec.insert('hh')\n",
    "                for seg in sec:\n",
    "                    seg.hh.gnabar = 0.12  # Sodium conductance in S/cm2\n",
    "                    seg.hh.gkbar = 0.036  # Potassium conductance in S/cm2\n",
    "        \n",
    "        for sec in self.dend:\n",
    "            sec.insert('hh')\n",
    "            for seg in sec:\n",
    "                seg.hh.gnabar = 0.12  # Sodium conductance in S/cm2\n",
    "                seg.hh.gkbar = 0.036  # Potassium conductance in S/cm2\n",
    "                \n",
    "        for sec in self.axon:\n",
    "            sec.insert('hh')\n",
    "            for seg in sec:    \n",
    "                seg.hh.gnabar = 0.12  # Sodium conductance in S/cm2\n",
    "                seg.hh.gkbar = 0.036  # Potassium conductance in S/cm2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the morphologies to work with\n",
    "\n",
    "<font size='3'> Running the next cell will result in an error message due to the morphology file, but don't pay attention to it, you will be able to run the simulations on these morphologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pyr1 = Cell('Pyr_01.swc','Pyr1','Pyr')\n",
    "Pyr2 = Cell('Pyr_02.swc','Pyr2','Pyr')\n",
    "Int1 = Cell('Int_01.swc','Int1','Int')\n",
    "cells_Pyr = [Pyr1, Pyr2]\n",
    "cells_Int = [Int1]\n",
    "cells = cells_Pyr + cells_Int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the number of sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cells_Pyr:\n",
    "    print('%s: %d apical sections, %d basal sections, %d soma sections and %d axon senctions' % (c.name,len(c.apic),len(c.dend), len(c.soma), len(c.axon)))\n",
    "for c in cells_Int:\n",
    "    print('%s: %d basal sections, %d soma sections and %d axon senctions' % (c.name,len(c.dend), len(c.soma), len(c.axon)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect two cells with an exponential synapse at given locations\n",
    "# returns the netcon\n",
    "def connect(source, target, weight = None, delay = 5, source_sec = None, source_neurite = 'axon', target_sec = None, target_neurite = 'dend', rng = None, seed = None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(seed)\n",
    "    \n",
    "    if weight is None:\n",
    "        weight = rng.uniform() # random weight\n",
    "    \n",
    "    target_neurite_ = getattr(target, target_neurite)\n",
    "    if target_sec is None:\n",
    "        target_sec = rng.integers(0, len(target_neurite_)) # random dendritic section\n",
    "    \n",
    "    source_neurite_ = getattr(source, source_neurite)\n",
    "    if source_sec is None:\n",
    "        source_sec = rng.integers(0, len(source_neurite_)) # random axonal section\n",
    "    \n",
    "    target_syn = h.ExpSyn(target_neurite_[target_sec](0.5))\n",
    "    target.synapses.append(target_syn) # store synapse\n",
    "    \n",
    "    netcon = h.NetCon(source_neurite_[source_sec](0.5)._ref_v, target_syn, sec=source_neurite_[source_sec])\n",
    "    netcon.weight[0] = weight\n",
    "    netcon.delay = delay\n",
    "    \n",
    "    print('Connected cells %s::%s[%d] -> %s::%s[%d] with weight %g and delay %g' % (source.name,source_neurite,source_sec,target.name,target_neurite,target_sec,weight,delay))\n",
    "    return netcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netcons = [] # save the netcons in case we want to modify them later\n",
    "\n",
    "seed = 1234 # specify seed for replicability of all that follows\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "# Connect Pyr2 and Int1 to Pyr1\n",
    "nc = connect(Pyr2,Pyr1,rng = rng,weight = 0.1)\n",
    "netcons.append(nc)\n",
    "nc = connect(Int1,Pyr1,rng = rng,weight = 0.1,target_neurite='soma')\n",
    "netcons.append(nc)\n",
    "\n",
    "# Connect Pyr1 and Int1 to Pyr2\n",
    "nc = connect(Pyr1,Pyr2,rng = rng,weight = 0.1)\n",
    "netcons.append(nc)\n",
    "nc = connect(Int1,Pyr2,rng = rng,weight = 0.1,target_neurite='soma')\n",
    "netcons.append(nc)\n",
    "\n",
    "# Connect Pyr1 and Pyr2 to Int1\n",
    "nc = connect(Pyr1,Int1,rng = rng,weight = 0.1)\n",
    "netcons.append(nc)\n",
    "nc = connect(Pyr2,Int1,rng = rng,weight = 0.1)\n",
    "netcons.append(nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place exponential synapses in random cell sections\n",
    "\n",
    "# Exponential synapses\n",
    "synapses = []\n",
    "for cell in cells:\n",
    "    sec = rng.integers(0, len(cell.dend))\n",
    "    syn = h.ExpSyn(cell.dend[sec](0.5))\n",
    "    syn.tau = 2 # ms\n",
    "    print('ExpSyn created at %s::%s[%s] with tau = %g' % (cell.name,\"dend\",sec,syn.tau))\n",
    "    synapses.append(syn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup stimulator per cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stimulators for synapses\n",
    "stims = []\n",
    "stim_nc = []\n",
    "for syn in synapses:\n",
    "    stim = h.VecStim()\n",
    "    nc = h.NetCon(stim, syn)\n",
    "    nc.weight[0] = 0.5 # In units of [nS] due to the gmax scaling factor in our .mod file\n",
    "    stims.append(stim)\n",
    "    stim_nc.append(nc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup stimulation times: Poissonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elephant.spike_train_generation as elstg\n",
    "import quantities as pq\n",
    "\n",
    "# Create a Poissonian spike train\n",
    "stim_rate = 60 * pq.Hz\n",
    "stim_tstart = 5 * pq.ms\n",
    "stim_tstop = 300 * pq.ms\n",
    "\n",
    "stim_times = []\n",
    "for stim in stims:\n",
    "    sptimes = elstg.homogeneous_poisson_process(stim_rate, stim_tstart, stim_tstop, as_array = True)\n",
    "    spvec = h.Vector(sptimes)\n",
    "    stim.play(spvec) # make stimulator fire at these times\n",
    "    stim_times.append(sptimes)\n",
    "    print(sptimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_cells = [Pyr1, Pyr2, Int1]\n",
    "\n",
    "somaV = []\n",
    "for cell in recording_cells:\n",
    "    s = h.Vector().record(cell.soma[0](0.5)._ref_v)\n",
    "    somaV.append(s)\n",
    "\n",
    "time = h.Vector().record(h._ref_t)\n",
    "sim_tstop = 300\n",
    "\n",
    "h.finitialize(-65)\n",
    "h.continuerun(sim_tstop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot voltage traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "for cell,V,color in zip(recording_cells,somaV,colors):\n",
    "    ax.plot(time, V, label=cell.name, color=color)\n",
    "\n",
    "ax.set_xlim((0,sim_tstop))\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spike detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo import AnalogSignal\n",
    "\n",
    "def spike_detector(voltage, threshold):\n",
    "    # convert Neuron recording (voltage) to neo.AnalogSignal\n",
    "    sig = AnalogSignal(voltage,units = pq.mV,sampling_period = 0.025 * pq.ms) # dt = 0.025 ms\n",
    "    # peak locations\n",
    "    spike_time = elstg.peak_detection(sig,threshold = threshold * pq.mV,format = 'raw')\n",
    "    return spike_time * 1000 # in ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_trains = []\n",
    "for V,st in zip(somaV,stim_times):\n",
    "    spk = spike_detector(V, -20.0) # tune threshold as needed\n",
    "    spike_trains.append(spk) # add cell spikes\n",
    "    spike_trains.append(st)  # add stim spikes\n",
    "    \n",
    "name_lst = [[_.name,_.name + '_stim'] for _ in recording_cells]\n",
    "name_lst = [x for sub in name_lst for x in sub] # https://stackoverflow.com/a/952952\n",
    "\n",
    "colors = ['blue', 'black', 'red', 'black', 'green', 'black']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "for (i,name),spikes,color in zip(enumerate(name_lst),spike_trains,colors):\n",
    "    ymin = 2 * i * -0.1\n",
    "    ymax = 2 * i * -0.1 - 0.1\n",
    "    ax.vlines(spikes, ymin=ymin, ymax=ymax, color=color, label=name)\n",
    "\n",
    "ax.set_xlim((0,sim_tstop))\n",
    "ax.set_xlabel(\"Time [ms]\")\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Put a legend below current axis\n",
    "ax.legend(bbox_to_anchor=(1.12, 1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single Spike train statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elephant.statistics as elstat\n",
    "\n",
    "for x,s in zip(name_lst,spike_trains):\n",
    "    print(x)\n",
    "    fr = elstat.mean_firing_rate(s) * 1000\n",
    "    print('Mean firing rate = %g Hz' % fr)\n",
    "    # Inter-spike intervals\n",
    "    isi = elstat.isi(s)\n",
    "    cv = elstat.cv(isi)\n",
    "    print('CV of ISI = %g' % cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Correlation analysis between spike trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo import SpikeTrain\n",
    "from elephant.conversion import BinnedSpikeTrain\n",
    "import elephant.spike_train_correlation as elstc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise correlation histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Pick only cell spike trains (saved in even entries of spike_trains)\n",
    "cell_names = [x for i,x in enumerate(name_lst) if i % 2 == 0]\n",
    "cell_spikes = [x for i,x in enumerate(spike_trains) if i % 2 == 0]\n",
    "\n",
    "binsize = 10 * pq.ms # 10 ms bin\n",
    "allspikes = [SpikeTrain(x * pq.ms, t_stop = sim_tstop * pq.ms) for x in cell_spikes]\n",
    "binned_spikes = [BinnedSpikeTrain(x, binsize = binsize) for x in allspikes]\n",
    "\n",
    "for a,b in itertools.combinations(zip(cell_names,binned_spikes), 2):\n",
    "    cch, lags = elstc.cross_correlation_histogram(a[1],b[1],border_correction=False)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(\"Cross-correlation of {} and {}\".format(a[0],b[0]))\n",
    "    ax.set_xlabel(\"Lag [ms]\")\n",
    "    plt.plot(lags * binsize,cch)\n",
    "    plt.axvline(0,ls='--',color='black',lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We bin the spikes in both cell and stim spikes\n",
    "allspikes = [SpikeTrain(x * pq.ms, t_stop = sim_tstop * pq.ms) for x in spike_trains]\n",
    "binned_spikes = BinnedSpikeTrain(allspikes, binsize = 10 * pq.ms) # 10 ms bin\n",
    "# Correlation coefficient matrix between all spike trains\n",
    "cc = elstc.corrcoef(binned_spikes)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "im = ax.imshow(cc, cmap=\"coolwarm\", vmin=-1.0, vmax=1.0, origin = 'upper')\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(name_lst)))\n",
    "ax.set_yticks(np.arange(len(name_lst)))\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels(name_lst)\n",
    "ax.set_yticklabels(name_lst)\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for i in range(len(name_lst)):\n",
    "    for j in range(len(name_lst)):\n",
    "        text = ax.text(j, i, np.round(cc[i, j],4),\n",
    "                       ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "ax.set_title('Pairwise Pearson correlation coefficients')\n",
    "plt.colorbar(im)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Neuron",
   "language": "python",
   "name": "neuron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
