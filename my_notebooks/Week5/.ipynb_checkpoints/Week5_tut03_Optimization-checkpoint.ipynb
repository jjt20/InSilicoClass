{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size = \"10\"> Week 5 - Single Cell Electrophysiology<center>\n",
    "<center><font size = \"8\">Tutorial 03: Parameter Optimization<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"3\"><font color = \"blue\"> In this tutorial you will optimize the soma conductances of a ball and stick cell model.\n",
    "    \n",
    "<font size = \"3\"><font color = \"blue\">The main goal of the tutorial is that you understand what is an optimization and what are the steps of a genetic algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Parameter Optimization?\n",
    "<font size='3'>A fancy name for training the selection of parameter values, which are optimal in some desired sense (eg. minimize an objective function you choose over a dataset you choose)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Parameters to be optimized.\n",
    "\n",
    "<font size='3'>First we need to know what do we want to optimize. A parameter can be in two states: frozen and not frozen. When a parameter is frozen it has an exact value, otherwise it only has some bounds but the exact value is not known yet. In this tutorial we will focus on optimizing the parameters at the soma.\n",
    "    \n",
    "<font size='3'>Let's create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load usefull packages\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from neuron import h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sections\n",
    "soma = h.Section(name='soma')\n",
    "dend = h.Section(name='dend')\n",
    "\n",
    "# Topology\n",
    "dend.connect(soma(1))\n",
    "\n",
    "# Geometry (frozen parameters)\n",
    "soma.L = soma.diam = 12.6157 # µm\n",
    "dend.L = 200                 # µm\n",
    "dend.diam = 1                # µm\n",
    "h.define_shape() # Translate into 3D points.\n",
    "\n",
    "# Biophysics\n",
    "for sec in h.allsec():\n",
    "    sec.Ra = 100    # Axial resistance in Ohm * cm (frozen)\n",
    "    sec.cm = 1      # Membrane capacitance in micro Farads / cm^2 (frozen)\n",
    "\n",
    "# Insert active Hodgkin-Huxley current in the soma\n",
    "soma.insert('hh')\n",
    "for seg in soma:\n",
    "    seg.hh.gnabar = 0.25  # Sodium conductance in S/cm2. [0, 1] (NOT frozen)\n",
    "    seg.hh.gkbar = 0.1    # Potassium conductance in S/cm2. [0, 1] (NOT frozen)\n",
    "    seg.hh.gl = 0.0003    # Leak conductance in S/cm2 (fix)\n",
    "    seg.hh.el = -54.3     # Reversal potential in mV (fix)\n",
    "\n",
    "# Insert passive current in the dendrite\n",
    "dend.insert('pas')\n",
    "for seg in dend:\n",
    "    seg.pas.g = 0.001  # Passive conductance in S/cm2 (frozen)\n",
    "    seg.pas.e = -65    # Leak reversal potential mV (frozen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3'>So in this case we only have two not-frozen or variable parameters: gnabar and gkbar.\n",
    "\n",
    "<font size='3'>In the code above we have already asigned default parameters to these variables. Let's see how the cell behaves under two different stimulations during a current clamp experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject current steps into the soma\n",
    "stim_amp = [0.1, 0.5]\n",
    "\n",
    "# Define plots\n",
    "fig1, ax1 = plt.subplots(figsize=(15,3))\n",
    "ax1.set(xlabel = 't (ms)', ylabel = 'V (mV)')\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(15,3))\n",
    "ax2.set(xlabel = 't (ms)', ylabel = 'I (nA)')\n",
    "\n",
    "# Stimulation\n",
    "for sa in stim_amp:  \n",
    "    # Place a stimulation electrode in the middle of the soma\n",
    "    stim = h.IClamp(soma(0.5))         \n",
    "    stim.delay = 100   # stim delay (ms)\n",
    "    stim.dur = 50      # stim duration (ms)\n",
    "    stim.amp = sa      # stim amplitude (nA)    \n",
    "    # Initialize NEURON vectors to record time, voltage and current\n",
    "    # time vector\n",
    "    rec_t = h.Vector()\n",
    "    rec_t.record(h._ref_t)\n",
    "    # membrame potential vector\n",
    "    rec_v_soma = h.Vector()\n",
    "    rec_v_soma.record(soma(0.5)._ref_v)\n",
    "    # current\n",
    "    rec_i = h.Vector()\n",
    "    rec_i.record(stim._ref_i)\n",
    "\n",
    "    # Initialize and run a simulation\n",
    "    h.load_file('stdrun.hoc')\n",
    "    h.finitialize(-65)\n",
    "    h.continuerun(200)\n",
    "    \n",
    "    ax1.plot(rec_t, rec_v_soma)\n",
    "    ax2.plot(rec_t, rec_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3'>We see that for stim_amp = 0.1 nA the cell fires one action potential, while if stim_amp = 0.5 nA the cell fires 5 Action potentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Optimize cell conductances through a genetic algorithm\n",
    "\n",
    "<font size='3'>Now, instead of asigning default values for the conductances, we will try to find the conductances that make our cell behavies as we want. We will find the optimal values by using a genetic algorithm (GA).\n",
    "\n",
    "<font size='3'>The GA is a method for solving both constrained and unconstrained optimization problems that is based on natural selection, the process that drives biological evolution. The genetic algorithm repeatedly modifies a population of individual solutions. At each step, the genetic algorithm selects individuals at random from the current population to be parents and uses them to produce the children for the next generation. Over successive generations, the population \"evolves\" toward an optimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3'>Let's start from zero.\n",
    "\n",
    "<font size='5'><font color='red'>RESTART YOUR KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load usefull packages\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from neuron import h\n",
    "\n",
    "# Cretae ball and stick model\n",
    "# Create sections\n",
    "soma = h.Section(name='soma')\n",
    "dend = h.Section(name='dend')\n",
    "\n",
    "# Topology\n",
    "dend.connect(soma(1))\n",
    "# Geometry\n",
    "soma.L = soma.diam = 12.6157 # microns\n",
    "dend.L = 200                 # microns\n",
    "dend.diam = 1                # microns\n",
    "h.define_shape() # Translate into 3D points.\n",
    "\n",
    "# Biophysics\n",
    "for sec in h.allsec():\n",
    "    sec.Ra = 100    # Axial resistance in Ohm * cm\n",
    "    sec.cm = 1      # Membrane capacitance in micro Farads / cm^2\n",
    "\n",
    "# Insert active Hodgkin-Huxley current in the soma\n",
    "# Now we won't include the values for gkbar and gnabar\n",
    "soma.insert('hh')\n",
    "for seg in soma:\n",
    "    #seg.hh.gnabar = 0.25  # Sodium conductance in S/cm2. [0, 1]\n",
    "    #seg.hh.gkbar = 0.1  # Potassium conductance in S/cm2. [0, 1]\n",
    "    seg.hh.gl = 0.0003    # Leak conductance in S/cm2\n",
    "    seg.hh.el = -54.3     # Reversal potential in mV\n",
    "\n",
    "# Insert passive current in the dendrite\n",
    "dend.insert('pas')\n",
    "for seg in dend:\n",
    "    seg.pas.g = 0.001  # Passive conductance in S/cm2\n",
    "    seg.pas.e = -65    # Leak reversal potential mV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efel\n",
    "\n",
    "# Create a function of the simulation that will give us the result for the different population members\n",
    "def stimulation(amp):\n",
    "    stim = h.IClamp(soma(0.5))         \n",
    "    stim.delay = 100   # stim delay (ms)\n",
    "    stim.dur = 50     # stim duration (ms)\n",
    "    stim.amp = amp    # stim amplitude (nA)    \n",
    "    # Initialize NEURON vectors to record time, voltage and current\n",
    "    # time vector\n",
    "    rec_t = h.Vector()\n",
    "    rec_t.record(h._ref_t)\n",
    "    # membrame potential vector\n",
    "    rec_v_soma = h.Vector()\n",
    "    rec_v_soma.record(soma(0.5)._ref_v)\n",
    "    # current\n",
    "    rec_i = h.Vector()\n",
    "    rec_i.record(stim._ref_i)\n",
    "\n",
    "    # Initialize and run a simulation\n",
    "    h.load_file('stdrun.hoc')\n",
    "    h.finitialize(-65)\n",
    "    h.continuerun(200)\n",
    "    \n",
    "    trace = {'T': rec_t, 'V': rec_v_soma, 'stim_start': [100], 'stim_end': [200]}\n",
    "\n",
    "    feature_values = efel.getFeatureValues([trace], ['Spikecount'])[0]\n",
    "    \n",
    "    return feature_values\n",
    "\n",
    "# RUN to test\n",
    "feat = stimulation(0.5)\n",
    "print(feat['Spikecount'][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create a starting random population\n",
    "\n",
    "<font size='3'>The first step will be to create a random population of [gnabar, gkbar], knowing that the values for both variables are between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import efel\n",
    "\n",
    "def create_starting_population(gna_min, gna_max, gk_min, gk_max, pop_size):\n",
    "    # Set up an initial array of all zeros\n",
    "    population = np.zeros((pop_size, 2))\n",
    "    for p in range(pop_size):\n",
    "        gna = random.uniform(gna_min, gna_max)\n",
    "        gk = random.uniform(gk_min, gk_max)\n",
    "        population[p][0] = gna\n",
    "        population[p][1] = gk\n",
    "    return population\n",
    "\n",
    "# RUN to test\n",
    "gna_min = 0\n",
    "gna_max = 1\n",
    "gk_min = 0\n",
    "gk_max = 1\n",
    "pop_size = 10\n",
    "\n",
    "pop = create_starting_population(gna_min, gna_max, gk_min, gk_max, pop_size)\n",
    "print (pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate fitness of population\n",
    "\n",
    "<font size='3'>In GAs we refer to how good each individual in the population is as ‘fitness’. The calculate_fitness function will be the evaluation procedure you wish to apply in your algorithm. In this example we are going to return the number of genes (elements) in a potential solution (chromosome) that match our f=reference standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness(population, goal1, stim_amp1, goal2, stim_amp2):\n",
    "    scores = []\n",
    "    for pop in population:\n",
    "        gna = pop[0]\n",
    "        gk = pop[1]\n",
    "        # Introduce mechanisms in the ball and stick model\n",
    "        soma.insert('hh')\n",
    "        for seg in soma:\n",
    "            seg.hh.gnabar = gna  # Sodium conductance in S/cm2. [0, 1]\n",
    "            seg.hh.gkbar = gk  # Potassium conductance in S/cm2. [0, 1]\n",
    "        fits = []\n",
    "        for g, st in zip([goal1, goal2], [stim_amp1, stim_amp2]):\n",
    "            spike_count = stimulation(st) # 0.5 is the amplitud stimulation\n",
    "            value = spike_count['Spikecount'][0]\n",
    "            fit = np.abs(g - value)\n",
    "            fits.append(fit)\n",
    "        scores.append(np.mean(fits))\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "# RUN to test\n",
    "stim_amp1 = 0.1 # nA\n",
    "goal1 = 1 # spike count number\n",
    "stim_amp2 = 0.5 # nA\n",
    "goal2 = 5 # spike count number\n",
    "\n",
    "fit_scor = calculate_fitness(pop, goal1, stim_amp1, goal2, stim_amp2)\n",
    "print(fit_scor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Choosing individuals to breed with tournament selection\n",
    "\n",
    "<font size='3'>Genetic algorithms mimic biology in that the individuals with the best fitness scores are most likely to breed and pass on their genes. But we do not simply take all the best individuals from our population to breed, as this might risk ‘in-breeding’. Rather, we use a method that means better individuals are moire likely to breed, but low fitness individuals at times may be chosen to breed.\n",
    "\n",
    "<font size='3'>In tournament selection we first choose two individuals at random from our population (it is possible that two low fitness individuals may be chosen). We then pass those individuals to a ‘tournament’ where the individual with the highest fitness will be chosen.\n",
    "\n",
    "<font size='3'>It is possible to further modify this so that the highest fitness individual will win with a given probability, but we will keep it simple here and have the highest fitness individual always winning. It is also possible to have more than two individuals in a tournament. The more individuals in a tournament the more the picked population will be biased towards the highest fitness individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_individual_by_tournament(population, scores):\n",
    "    # Get population size\n",
    "    population_size = len(scores)\n",
    "    \n",
    "    # Pick individuals for tournament\n",
    "    fighter_1 = random.randint(0, population_size-1)\n",
    "    fighter_2 = random.randint(0, population_size-1)\n",
    "    \n",
    "    # Get fitness score for each\n",
    "    fighter_1_fitness = scores[fighter_1]\n",
    "    fighter_2_fitness = scores[fighter_2]\n",
    "    \n",
    "    # Identify individual with smallest fitness\n",
    "    # Fighter 1 will win if score are equal\n",
    "    if fighter_1_fitness <= fighter_2_fitness:\n",
    "        winner = fighter_1\n",
    "    else:\n",
    "        winner = fighter_2\n",
    "    \n",
    "    # Return winner\n",
    "    return population[winner, :]\n",
    "\n",
    "# RUN to test\n",
    "parent1 = select_individual_by_tournament(pop, fit_scor)\n",
    "parent2 = select_individual_by_tournament(pop, fit_scor)\n",
    "parent3 = select_individual_by_tournament(pop, fit_scor)\n",
    "parent4 = select_individual_by_tournament(pop, fit_scor)\n",
    "parent5 = select_individual_by_tournament(pop, fit_scor)\n",
    "parent6 = select_individual_by_tournament(pop, fit_scor)\n",
    "print(parent1)\n",
    "print(parent2)\n",
    "print(parent3)\n",
    "print(parent4)\n",
    "print(parent5)\n",
    "print(parent6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Producing children from parents – crossover\n",
    "\n",
    "<font size='3'>When two individuals are chosen, the next step is to produce ‘children’ from them. We produce these children by ‘crossover’ mix of their values. One ‘child’ will take the gnabar from parent 1 and gkbar from parent 2. The result is a mix of \"genes\" from each parent. The second ‘child’ will be the opposite of this.\n",
    "\n",
    "<font size='3'>It is possible to have more than one crossover point, but we will keep it simple and have a single crossover point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_by_crossover(parent_1, parent_2):\n",
    "    # Create children. np.hstack joins two arrays\n",
    "    child_1 = np.hstack((parent_1[0],parent_2[1]))  \n",
    "    child_2 = np.hstack((parent_1[1],parent_2[0]))    \n",
    "    # Return children\n",
    "    return child_1, child_2\n",
    "\n",
    "child1, child2 = breed_by_crossover(parent1, parent2)\n",
    "child3, child4 = breed_by_crossover(parent3, parent4)\n",
    "child5, child6 = breed_by_crossover(parent5, parent6)\n",
    "\n",
    "print (child1)\n",
    "print (child2)\n",
    "print (child3)\n",
    "print (child4)\n",
    "print (child5)\n",
    "print (child6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Random mutation of genes\n",
    "\n",
    "<font size='3'>In evolution sometimes genes are copied incorrectly. This change may be harmful or beneficial. We mimic this by having a certain probability of that a conductance (\"gene\") becomes switched.\n",
    "\n",
    "<font size='3'>Typically this probability is low (e.g. 0.005), though it can be made to be flexible (e.g. increase mutation rate if progress has stalled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_mutate_population(population, mutation_probability):  \n",
    "    for p in population:\n",
    "        filt = random.random()\n",
    "        if filt < mutation_probability:\n",
    "            # Apply random mutation\n",
    "            gna = random.uniform(0, 1)\n",
    "            p[0] = gna\n",
    "            gk = random.uniform(0, 1)\n",
    "            p[1] = gk\n",
    "        else:\n",
    "            pass\n",
    "    # Return mutation population\n",
    "    return population\n",
    "\n",
    "#RUN to test\n",
    "new_pop = np.stack((child1, child2))\n",
    "print (new_pop)\n",
    "\n",
    "mut_pop = randomly_mutate_population(new_pop, 0.25)\n",
    "print (mut_pop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Putting it all together\n",
    "\n",
    "<font size='3'>We’ve defined all the functions we need. Now let’s put it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set general parameters\n",
    "population_size = 50\n",
    "maximum_generation = 5\n",
    "best_score_progress = [] # Tracks progress\n",
    "gna_min = 0.0\n",
    "gna_max = 1.0\n",
    "gk_min = 0.0\n",
    "gk_max = 1.0\n",
    "stim_amp2 = 0.1 # nA\n",
    "goal2 = 1 # 1 spikes is our goal\n",
    "stim_amp2 = 0.5 # nA\n",
    "goal2 = 5 # 5 spikes is our goal\n",
    "\n",
    "# Create starting population\n",
    "# RUN\n",
    "population = create_starting_population(gna_min, gna_max, gk_min, gk_max, population_size)\n",
    "\n",
    "# Display best score in starting population\n",
    "fit_scores = calculate_fitness(population, goal1, stim_amp1, goal2, stim_amp2)\n",
    "best_score = np.min(fit_scores)\n",
    "\n",
    "for i in range(len(fit_scores)):\n",
    "    if fit_scores[i] == best_score:\n",
    "        gna = population[i][0]\n",
    "        gk = population[i][1]\n",
    "        print ('Starting best score: %.1f (gna = %.2f, gk = %.2f)' %(best_score, gna, gk))\n",
    "        best_score_progress.append(best_score)\n",
    "    \n",
    "# Now we'll go through the generations of genetic algorithm\n",
    "for generation in range(maximum_generation):\n",
    "    # Create an empty list for new population\n",
    "    new_population = []\n",
    "    \n",
    "    # Create new popualtion generating two children at a time\n",
    "    for i in range(int(population_size/2)):\n",
    "        parent_1 = select_individual_by_tournament(population, fit_scores)\n",
    "        parent_2 = select_individual_by_tournament(population, fit_scores)\n",
    "        child_1, child_2 = breed_by_crossover(parent_1, parent_2)\n",
    "        new_population.append(child_1)\n",
    "        new_population.append(child_2)\n",
    "    \n",
    "    # Replace the old population with the new one\n",
    "    population = np.array(new_population)\n",
    "    \n",
    "    # Apply mutation\n",
    "    mutation_rate = 0.0020\n",
    "    population = randomly_mutate_population(population, mutation_rate)\n",
    "\n",
    "    # Score best solution, and add to tracker\n",
    "    pop_scores = calculate_fitness(population, goal1, stim_amp1, goal2, stim_amp2)\n",
    "    best_score = np.min(pop_scores)\n",
    "    \n",
    "    for i in range(len(pop_scores)):\n",
    "        if pop_scores[i] == best_score:\n",
    "            gna = population[i][0]\n",
    "            gk = population[i][1]\n",
    "            print ('Generation %s best score: %.1f (gna = %.2f, gk = %.2f)' %(generation, best_score, gna, gk))\n",
    "            best_score_progress.append(best_score)\n",
    "        \n",
    "# GA has completed required generation\n",
    "\n",
    "# Plot progress\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(best_score_progress)\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Best score (% target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimazing is not a simple problem.\n",
    "\n",
    "<font size = \"3\">This is only a very simple example of what an optimization is, at it gave us many different solutions. Usually we will optimize many more parameters together which is really a complex task, and it will give us only few potential solutions. As this is such a big problem, there are dedicated libraries such as [BluePyOpt](https://bluepyopt.readthedocs.io/en/latest/). BluePyOpt is an extensible framework for data-driven model parameter optimisation that wraps and standardizes several existing open-source tools. It simplifies the task of creating and sharing these optimisations, and the associated techniques and knowledge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
